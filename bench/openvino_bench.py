"""Simple OpenVINO benchmark harness.

Provides a safe no-op fallback when OpenVINO isn't installed so developers
can run the benchmark script locally without requiring OpenVINO.

Usage:
    python -m bench.openvino_bench --runs 50 --size 224
"""
from __future__ import annotations

import time
import statistics
from typing import List
import importlib.util


def _has_openvino() -> bool:
    try:
        return importlib.util.find_spec("openvino.runtime") is not None
    except Exception:
        return False


def synthetic_workload(size: int = 224) -> List[float]:
    """Run a synthetic workload that resembles an inference loop.

    If OpenVINO is available the function will attempt to load a tiny
    compiled model (not provided here) and run inference; otherwise it will
    simulate compute by running a tight CPU-bound loop to provide timings.
    """
    timings: List[float] = []

    # If model runtime is available but no model path provided, we still
    # simulate a small numeric workload. Actual model runs are handled by
    # `run_model_workload` when a model path is given.
    try:
        import numpy as np  # type: ignore

        for _ in range(10):
            inp = np.random.rand(1, 3, size, size).astype("float32")
            start = time.perf_counter()
            # No real model available â€” simulate a small delay
            _ = inp.sum()
            end = time.perf_counter()
            timings.append(end - start)
        return timings
    except Exception:
        # Fallback to pure-Python workload
        pass

    # Synthetic CPU-bound workload as fallback
    for _ in range(20):
        start = time.perf_counter()
        s = 0.0
        for i in range(size * size):
            s += (i % 7) * 0.000001
        end = time.perf_counter()
        timings.append(end - start)

    return timings


def summarize(times: List[float]) -> dict:
    if not times:
        return {}
    return {
        "count": len(times),
        "mean_s": statistics.mean(times),
        "median_s": statistics.median(times),
        "p90_s": statistics.quantiles(times, n=10)[-1],
        "min_s": min(times),
        "max_s": max(times),
    }


def run_model_workload(model_path: str, size: int = 224, runs: int = 20) -> List[float]:
    """Run inference using OpenVINO model at `model_path` and return per-run timings.

    The model is expected to be a compiled OpenVINO IR (XML+BIN) or other
    format supported by `openvino.runtime.Core`.
    """
    timings: List[float] = []
    try:
        import numpy as np  # type: ignore
        import openvino.runtime as ov  # type: ignore

        core = ov.Core()
        model = core.read_model(model=model_path)
        compiled = core.compile_model(model, "CPU")
        inputs = compiled.inputs
        # Prepare a random input with matching shape if possible
        inp_shape = None
        if inputs:
            inp_shape = tuple(int(x) for x in inputs[0].shape)

        for _ in range(runs):
            if inp_shape:
                data = np.random.rand(*inp_shape).astype("float32")
                feed = {inputs[0].any_name: data}
            else:
                data = np.random.rand(1, 3, size, size).astype("float32")
                feed = {compiled.inputs[0].any_name: data}

            start = time.perf_counter()
            # Use synchronous infer (simple and portable)
            compiled.create_infer_request().infer(feed)
            end = time.perf_counter()
            timings.append(end - start)

        return timings
    except Exception:
        # If any step fails, fall back to synthetic timings
        return synthetic_workload(size=size)


if __name__ == "__main__":
    import argparse
    import json
    from pathlib import Path

    try:
        import matplotlib.pyplot as plt  # type: ignore
    except Exception:
        plt = None

    parser = argparse.ArgumentParser(description="OpenVINO benchmark harness")
    parser.add_argument("--runs", type=int, default=20)
    parser.add_argument("--size", type=int, default=224)
    parser.add_argument("--model-path", type=str, default="", help="Optional OpenVINO model path (XML/IR or other supported)")
    parser.add_argument("--out", type=str, default="", help="Optional output JSON path to write results")
    parser.add_argument("--plot", action="store_true", help="If set and matplotlib available, save a PNG timing plot next to the JSON output")
    args = parser.parse_args()

    all_times = []
    if args.model_path:
        all_times = run_model_workload(args.model_path, size=args.size, runs=args.runs)
    else:
        for _ in range(max(1, args.runs // 5)):
            t = synthetic_workload(size=args.size)
            all_times.extend(t)

    stats = summarize(all_times)
    print("OpenVINO bench (or synthetic fallback) results:")
    for k, v in stats.items():
        print(f"  {k}: {v}")

    # Write results to JSON if requested
    if args.out:
        out_path = Path(args.out)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        payload = {"stats": stats, "times": all_times}
        with out_path.open("w", encoding="utf-8") as fh:
            json.dump(payload, fh, indent=2)
        print(f"Wrote results to {out_path}")

        # Optional plot
        if args.plot and plt is not None:
            try:
                fig, ax = plt.subplots()
                ax.plot(all_times, marker="o")
                ax.set_xlabel("run")
                ax.set_ylabel("seconds")
                ax.set_title("OpenVINO bench timings")
                png_path = out_path.with_suffix(".png")
                fig.savefig(png_path)
                print(f"Wrote timing plot to {png_path}")
            except Exception:
                print("Failed to generate plot; continuing")
